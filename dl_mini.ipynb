{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSDeS0XblAOQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import random\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Datasets"
      ],
      "metadata": {
        "id": "DMQaM-sPl7Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#datasets and loaders - using torchvision; standard transformation\n",
        "\n",
        "random.seed(28)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZBUXpOFl2p5",
        "outputId": "a3db4039-abb3-40fd-867a-02f0eeb5080a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided CIFAR10 train and custom datasets were downloaded locally then uploaded to Google Drive for easier access. The code to download the train dataset has been commented out as we ultimately decided to use the torchvision datasets for training"
      ],
      "metadata": {
        "id": "ikiRk-4nJhkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Import data from Google Drive\n",
        "\n",
        "# Read the test file, note that it has no labels and needs to be used with your model inference to predict outputs.\n",
        "\n",
        "#Test Dataset (Custom for Kaggle)\n",
        "def load_cifar_batch(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        batch = pickle.load(fo, encoding='bytes')\n",
        "    return batch\n",
        "\n",
        "# Load the batch\n",
        "# The path has been modified to reflect the location on our personal drive;\n",
        "\n",
        "cifar10_batch = load_cifar_batch('/content/drive/MyDrive/Colab Notebooks/cifar10/deep-learning-mini-project-spring-24-nyu/cifar_test_nolabels.pkl')\n",
        "#cifar10_batch_kaggle = load_cifar_batch('/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar_test_nolabels')\n",
        "\n",
        "# Extract images\n",
        "images = cifar10_batch[b'data']\n",
        "images = images.reshape(-1, 3, 32, 32)\n",
        "images_permuted = np.transpose(images, (0, 2, 3, 1)) # Kaggle Testset\n",
        "\n",
        "# plt.figure(figsize=(25, 8))\n",
        "# for i in range(20):\n",
        "#     plt.subplot(1, 20, i+1)\n",
        "#     plt.imshow(images_permuted[i])\n",
        "#     plt.axis('off')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# # Train Dataset - uploaded to Google Drive after downloading from Kaggle\n",
        "\n",
        "# def load_cifar_batch(file):\n",
        "#     with open(file, 'rb') as fo:\n",
        "#         dict = pickle.load(fo, encoding='bytes')\n",
        "#     return dict\n",
        "\n",
        "# # Specify the folder where the CIFAR-10 batch files are\n",
        "\n",
        "# cifar10_dir = '/content/drive/MyDrive/Colab Notebooks/cifar10/deep-learning-mini-project-spring-24-nyu/cifar-10-python/cifar-10-batches-py'\n",
        "# #cifar10_dir_kaggle = '/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar-10-python/cifar-10-batches-py'\n",
        "\n",
        "# # Load the label names\n",
        "# meta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\n",
        "# label_names = meta_data_dict[b'label_names']\n",
        "\n",
        "# # Load one batch for demonstration (e.g., data_batch_1)\n",
        "# batch_1_dict = load_cifar_batch(os.path.join(cifar10_dir, 'data_batch_1'))\n",
        "# batch_2_dict = load_cifar_batch(os.path.join(cifar10_dir, 'data_batch_2'))\n",
        "# batch_3_dict = load_cifar_batch(os.path.join(cifar10_dir, 'data_batch_3'))\n",
        "# batch_4_dict = load_cifar_batch(os.path.join(cifar10_dir, 'data_batch_4'))\n",
        "# batch_5_dict = load_cifar_batch(os.path.join(cifar10_dir, 'data_batch_5'))\n",
        "\n",
        "# # Combine the databatches into one training set\n",
        "# train_images = np.concatenate((batch_1_dict[b'data'], batch_2_dict[b'data'],batch_3_dict[b'data'],batch_4_dict[b'data'],batch_5_dict[b'data']), axis=0)\n",
        "# train_labels = np.concatenate((batch_1_dict[b'labels'], batch_2_dict[b'labels'],batch_3_dict[b'labels'],batch_4_dict[b'labels'],batch_5_dict[b'labels']), axis=0)\n",
        "\n",
        "# # Reshape the images\n",
        "# train_images = train_images.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "\n",
        "# # # Display 10 (random range) images and labels\n",
        "\n",
        "# # plt.figure(figsize=(20, 4))\n",
        "# # for i in range(23444,23454):\n",
        "# #     plt.subplot(1, 10, i-23443)\n",
        "# #     plt.imshow(train_images[i])\n",
        "# #     plt.title(label_names[train_labels[i]].decode('utf-8'))  # Decoding from bytes to string\n",
        "# #     plt.axis('off')\n",
        "# # plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdJfPqm1l2sB",
        "outputId": "384de572-6584-4655-c959-a393a49abbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loader Functions for Custom Test Data\n",
        "\n",
        "def create_test_loader(test_images, batch_size=64, shuffle=False):\n",
        "    # Step 1: Normalize the pixel values to the range [0, 1]\n",
        "    test_images = test_images / 255.0  # Assuming pixel values are in the range [0, 255]\n",
        "\n",
        "    # Step 2: Convert Numpy Array to PyTorch Tensor\n",
        "    test_images_tensor = torch.tensor(test_images, dtype=torch.float32)\n",
        "\n",
        "    # Step 3: Permute the dimensions to match the expected format (if necessary)\n",
        "    # For example, if the channel dimension is the first dimension, permute it to the last dimension\n",
        "    test_images_tensor = test_images_tensor.permute(0, 3, 1, 2)  # Assuming channel dimension is the last dimension\n",
        "\n",
        "    # Step 4: Create TensorDataset\n",
        "    test_dataset = TensorDataset(test_images_tensor)\n",
        "\n",
        "    # Step 5: Create DataLoader\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    return test_loader"
      ],
      "metadata": {
        "id": "0BnCYYT-nFlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Custom Test Loader\n",
        "testloader_custom = create_test_loader(images_permuted, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "1gJ4tLf3nf74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet Model:\n",
        "\n",
        "Input custom parameters as ints/lists in the order of number of layers (int), number of residual blocks in each layer(list), number of channels in each layer (list), kernel sizes in each layer (list), skip connection kernels in each layer (list), and pool size (int)\n",
        "\n",
        "Our model is based on the ResNet implementation from the [pytorch-cifar](https://github.com/kuangliu/pytorch-cifar) repository. Modifications have been made to adapt it to the specific requirements of this project."
      ],
      "metadata": {
        "id": "Aa17QuYjms-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, kernel_size, skip_kernel, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=kernel_size, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=skip_kernel, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, N, B, C, F, K, P, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = C[0]\n",
        "        self.block = BasicBlock\n",
        "        self.N = N                # No. of Residual Layers\n",
        "        self.B = B                # No. of Residual Blocks in Residual Layer i\n",
        "        self.C = C                # No. of channels in Residual Layer i\n",
        "        self.F = F                # Conv. kernel size in Residual Layer i\n",
        "        self.K = K                # Skip connection kernel size in Residual Layer i\n",
        "        self.P = P                # Average pool kernel size\n",
        "        self.layers = []          # layers container\n",
        "        self.S = [2] * N          # strides for layers\n",
        "        self.S[0] = 1\n",
        "\n",
        "        # Output Liner layer input dimension\n",
        "        self.outLayerInSize = C[N-1]*(32//(P*2**(N-1)))*(32//(P*2**(N-1)))\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, C[0], kernel_size=F[0], stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(C[0])\n",
        "\n",
        "        for i in range(N):\n",
        "            exec(\"self.layer{} = self._make_layer(self.block, self.C[{}], self.B[{}], self.F[{}], self.K[{}], self.S[{}])\"\\\n",
        "                .format(i+1,i,i,i,i,i))\n",
        "            exec(\"self.layers.append(self.layer{})\".format(i+1))\n",
        "        self.linear = nn.Linear(self.outLayerInSize, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, kernel_size, skip_kernel, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, kernel_size, skip_kernel, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        for layer in self.layers:\n",
        "            out = layer(out)\n",
        "        out = F.avg_pool2d(out, self.P)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "dh28RnZPl2xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Test Functions - to be used with the torchvision datasets"
      ],
      "metadata": {
        "id": "6Zsm02vim4F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_loader, criterion, optimizer, num_epochs=1):\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()  # Set the model to train mode\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU if available\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "            outputs = net(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute the loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Optimize\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n"
      ],
      "metadata": {
        "id": "rLRd19ocLJa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    model.to(device)  # Move model to the same device as the data\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)  # Move data to the same device as the model\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print('Accuracy of the network on the test images: %d %%' % (\n",
        "        100 * correct / total))\n"
      ],
      "metadata": {
        "id": "tjvcwk-Ql21y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict on Custom Test file and export to CSV\n",
        "\n",
        "The csv file will save directly to the Google Drive folder as a single column csv file. Using Google Sheets, we simply add the ID from 0 to 9999 and export as another csv file to upload to Kaggle"
      ],
      "metadata": {
        "id": "tdcnHOO7n4rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_csv(model, test_loader, output_csv):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    model.to(device)  # Move model to the GPU if available\n",
        "\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images = data[0].to(device)  # Move data to GPU if available\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())  # Append predicted labels to the list\n",
        "\n",
        "    # Save predictions to a CSV file - in this case, path is directly to Google Drive\n",
        "    df = pd.DataFrame({\"Labels\": predictions})\n",
        "    df.to_csv(f'/content/drive/MyDrive/Colab Notebooks/{output_csv}.csv', index=False)\n",
        "\n",
        "    print(f\"Predictions saved to {output_csv}\")\n"
      ],
      "metadata": {
        "id": "-Kv5Zl9wl24I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main"
      ],
      "metadata": {
        "id": "SyTqCyVwOydc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "gjDvMt3Il26b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tested a few different combinations of hyperparameters by specifying variable like below. Due to limited time and resources, we only trained for 2 epochs each with other parameters kept fixed. We have a recorded a few manually for the higher total parameter counts. Table can be found in our report."
      ],
      "metadata": {
        "id": "Bqat3pU6O14_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N=3\n",
        "B=[3,3,3]\n",
        "C=[64,128,256]\n",
        "F=[3,3,3]\n",
        "K=[1,1,1]\n",
        "P=4\n",
        "\n",
        "testnet = ResNet(N, B, C, F, K, P)\n",
        "testnet = testnet.to(device)"
      ],
      "metadata": {
        "id": "3IWiez9pKOlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(testnet.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "DCJRlBkql29g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train(testnet, trainloader, criterion, optimizer, num_epochs=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4rhKK68_ljr",
        "outputId": "c72abcac-6332-441d-a491-226cffde744f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Loss: 1.4157421163621544\n",
            "Epoch 2/2, Loss: 0.8524004436112195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(testnet, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBvpHXgNqT0l",
        "outputId": "6cf9b34b-c863-48ae-eb37-576016be1f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 71 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to limited time and resources, mainly from previous experimentation that we discarded, we chose the two most high performing hypoerparameter combinations with respect to training loss and accuracy to further train and observe. We initially trained for just 10 epochs added 5 more to make number of epochs 15. The accuracy improvement from 2 epochs to 10 was significant for both of our top parameters, but found improvement to be minor from 10 to 15; we expect similar results for even higher number of epochs."
      ],
      "metadata": {
        "id": "xYxgIlEhPV8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_1=[2,1,2,2]\n",
        "C_1=[64,128,256,256]\n",
        "F_1=[3,3,3,3]\n",
        "K_1=[1,1,1,1]\n",
        "P_1=4\n",
        "N_1=4\n",
        "\n",
        "first_resnet = ResNet(N_1, B_1, C_1, F_1, K_1, P_1)\n",
        "first_resnet = first_resnet.to(device)\n"
      ],
      "metadata": {
        "id": "sB1D8BNMqaEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the total number of parameters given hyperparameters; note that the summary is not present for all, but we have manually recorded results which can be found in our report.\n",
        "summary(first_resnet, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEXZyb3ZYhiZ",
        "outputId": "b8b17e1e-26a3-43bb-baf4-5b1fce8629e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-21            [-1, 256, 8, 8]             512\n",
            "           Conv2d-22            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-23            [-1, 256, 8, 8]             512\n",
            "           Conv2d-24            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-25            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 4, 4]             512\n",
            "           Conv2d-34            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 4, 4]             512\n",
            "           Conv2d-36            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-37            [-1, 256, 4, 4]             512\n",
            "       BasicBlock-38            [-1, 256, 4, 4]               0\n",
            "           Conv2d-39            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-40            [-1, 256, 4, 4]             512\n",
            "           Conv2d-41            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "       BasicBlock-43            [-1, 256, 4, 4]               0\n",
            "           Linear-44                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 4,909,642\n",
            "Trainable params: 4,909,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.63\n",
            "Params size (MB): 18.73\n",
            "Estimated Total Size (MB): 28.37\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(first_resnet.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "L8d8cgB_Y-n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(first_resnet, trainloader, criterion, optimizer, num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTLrqFALZGvb",
        "outputId": "67b9a139-aa76-4819-e590-8e6388cba118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3429175821387769\n",
            "Epoch 2/10, Loss: 0.8126889728840441\n",
            "Epoch 3/10, Loss: 0.6086656902072206\n",
            "Epoch 4/10, Loss: 0.4712365833407501\n",
            "Epoch 5/10, Loss: 0.35921292084219864\n",
            "Epoch 6/10, Loss: 0.2672442619249527\n",
            "Epoch 7/10, Loss: 0.1942061690515018\n",
            "Epoch 8/10, Loss: 0.13936921194193042\n",
            "Epoch 9/10, Loss: 0.10031987528590668\n",
            "Epoch 10/10, Loss: 0.06968409092166337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(first_resnet, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO-Z875jZJhi",
        "outputId": "a23f561c-2994-40d1-b351-e3054c084c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 82 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"first_resnet_10_eps_csv_file_acc_82\"\n",
        "\n",
        "save_csv(first_resnet, testloader_custom,file_name ) #should be about 52% on Kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDzfXEJdft9Y",
        "outputId": "e9ec6c62-71fa-4527-ed89-9b9d95d28912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to first_resnet_10_eps_csv_file_acc_82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B_2=[3,3,2,3]\n",
        "C_2=[64,128,128,256]\n",
        "F_2=[3,3,3,3]\n",
        "K_2=[1,1,1,1]\n",
        "P_2=4\n",
        "N_2=4\n",
        "\n",
        "second_resnet = ResNet(N_2, B_2, C_2, F_2, K_2, P_2)\n",
        "second_resnet = second_resnet.to(device)"
      ],
      "metadata": {
        "id": "a3CqnFGCZRUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(second_resnet.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "3vTudFCTbZY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(second_resnet, trainloader, criterion, optimizer, num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm_TvHuVbesQ",
        "outputId": "435dd55a-0dbe-4b9f-9636-457984dc48dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4326070944470166\n",
            "Epoch 2/10, Loss: 0.8585262776635587\n",
            "Epoch 3/10, Loss: 0.6372525906962528\n",
            "Epoch 4/10, Loss: 0.49743281851571053\n",
            "Epoch 5/10, Loss: 0.38908295226437506\n",
            "Epoch 6/10, Loss: 0.30441392069512163\n",
            "Epoch 7/10, Loss: 0.2282999128790156\n",
            "Epoch 8/10, Loss: 0.1725996220833392\n",
            "Epoch 9/10, Loss: 0.12559819755841944\n",
            "Epoch 10/10, Loss: 0.0938154758175362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(second_resnet, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5VslwO3bf0I",
        "outputId": "334e3009-28da-4869-8268-64b5022d1a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 82 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We purchasd 200 Compute Engines in total for Google Colab to use better performing GPUs. In this session alone, ran of out of memory per the error below, so we were unable to export the newer results as pdf."
      ],
      "metadata": {
        "id": "mHOsJpBQRX9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"second_resnet_10_eps_csv_file_acc_82\"\n",
        "\n",
        "save_csv(first_resnet, testloader_custom,file_name ) #should be about 52%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "oPN8KBRoocGS",
        "outputId": "91d5a2b3-8a84-41be-9bf2-b4c5a10fef1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.07 GiB is free. Process 87562 has 13.70 GiB memory in use. Of the allocated memory 10.23 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-10faea98dadb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"second_resnet_10_eps_csv_file_acc_82\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_resnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader_custom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m#should be about 52%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-e4fca0753ab5>\u001b[0m in \u001b[0;36msave_csv\u001b[0;34m(model, test_loader, output_csv)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Move data to GPU if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Append predicted labels to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-3aee7c2bdd1a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-3aee7c2bdd1a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m     )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.07 GiB is free. Process 87562 has 13.70 GiB memory in use. Of the allocated memory 10.23 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(first_resnet, trainloader, criterion, optimizer, num_epochs=5) # 15th epoch in total\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhThbTXwou0q",
        "outputId": "072e8222-8936-40c1-d0f1-01f3e202ce5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.054807147495246684\n",
            "Epoch 2/5, Loss: 0.055825584951267195\n",
            "Epoch 3/5, Loss: 0.05404582598539179\n",
            "Epoch 4/5, Loss: 0.0544479376459989\n",
            "Epoch 5/5, Loss: 0.056161193695629774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(first_resnet, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEdLRIi-o3P6",
        "outputId": "adb912a4-6258-4dda-8b95-a88483861819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 82 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(second_resnet, trainloader, criterion, optimizer, num_epochs=5) #15th epoch in total\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8XfF26FsGeM",
        "outputId": "abb7715d-14da-4826-ed77-f59f696ce3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.07381486251885665\n",
            "Epoch 2/5, Loss: 0.05470524840512127\n",
            "Epoch 3/5, Loss: 0.04191658935609079\n",
            "Epoch 4/5, Loss: 0.031857568946714904\n",
            "Epoch 5/5, Loss: 0.024241891359194797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(second_resnet, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1olUiYTFsXQq",
        "outputId": "91cb56db-b026-4067-e056-e5eaae6ef754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 84 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dfgf1QI-7c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 84% accuracy for the second_resnet after 15 epochs shows improvement -- vs 82% after 10 epochs. If this model was further trained and tested against the custom test set, we believe results would've been better, but that remains a hypothesis for now."
      ],
      "metadata": {
        "id": "7kFp2WYKR3qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We address this in our report in greater detail, but the biggest problem we encountered was the high discrepancy in our accuracy of the torchvision dataset and custom dataset for Kaggle, ~84% vs ~53%. This level of discrepancy occured throughout our entire project, which led us to discarding a bulk of our previous efforts. (our number of submission on Kaggle is low because we think we figured out the true labels for the test set, which we used for reference to not exhaust submissions)\n",
        "\n",
        "We saw other groups experience similar issues and tried suggestions in the Slack channels but were not successful. Some discrepancy is obviously expected -- and welcomed -- but a 30% gap warrants further exploration which we unfortunately did not get to."
      ],
      "metadata": {
        "id": "MYCso08OSYFc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3tAMS177S_tk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}